# Usability Evaluation
## Usability
Q: What is usability?
A: usability: ease with which ***people (users)*** can use a particular tool or object to achieve a specific ***goal (task)***

Q: Which aspects of usability are important (named at least three points)?
A: • aspects of usability:
– learnability: how easy to accomplish tasks the first time?
– efficiency: once learned, how quickly to complete tasks?
– memorability: how easy to reestablish proficiency after not having used a design for a period of time?
– errors: how many, how serious, how easy to recover?
– satisfaction: how pleasant to use the design?

## Heuristic Evaluation
use of design principles/heuristics to inspect an interface for usability problems.
evaluation only by developers or experts.

General approach:
take the interface and check for the interface guidelines/heuristics.

Number of evaluations:
– single inspector
– multiple inspectors

### Heuristic Evaluation: Individuals vs. Teams
• individual inspectors who look at an interface alone are recommended

• reasons:
– evaluation not influenced by others
– independent and unbiased
– greater variability in the kinds of errors found
– no overhead required to organize group meetings

• problem: some interfaces require groups, then use several independent groups

### Self-Guided vs. Scenario Exploration
• self-guided exploration
– open-ended exploration
– not necessarily task-directed
– good for exploring diverse aspects of the interface

• scenario exploration
– step through interface using a number of representative end user tasks (remember task-centered design)
– ensures problems found in relevant parts of the interface
– ensures that specific features of interest are evaluated
– limits scope of evaluation – problems may be missed

## Qualitative and Quantitative Evaluation
evaluation with ‘real’ people (users).

### Ethics
• Don’t waste the user’s time
– use pilot tests to debug experiments, questionnaires etc
– have everything ready before the user shows up

• Make users feel comfortable
– emphasize that it is the system that is being tested, not the user
– acknowledge that the software may have problems
– let users know they can stop at any time

• Maintain privacy
– tell user that individual test results will be completely confidential
• Inform the user
– explain any monitoring that is being used
– answer all user’s questions (but avoid bias)

• Only use volunteers
– user must sign an informed consent form

• Inform the user
– answer particular questions about the experiment that could
have biased the results before

### Qualitative vs. Quantitative Evaluation
• can test numeric or non-numeric criteria

• non-numeric (qualitative) criteria
– e.g., what techniques do people employ to reach a goal?
– e.g., what do people like or dislike about an interface?
– subjective opinions of people about interfaces

• numeric (quantitative) criteria
– e.g., how fast can someone achieve a goal?
– e.g., how precise are people in their interactions?
– e.g., how many mistakes do people make?
– quantitative comparison of techniques
– statistical evaluation: significance

### Qualitative Evaluation Techniques
#### Qualitative Evaluation Approaches
• naturalistic approaches:
observe in realistic settings
– pro: real-life situations
– con: hard to arrange and do, time-consuming, may not generalize easily

• usability engineering approaches:
observe in simulated settings
– pro: situation can be better controlled, easier and cheaper to arrange and do, less time-consuming
– con: changed context for interface use

#### Qualitative Evaluation Techniques
• direct observations: observe people while they are using a system
• interviews: investigate specific issues
• continuous evaluations: monitor system in use

##### Direct Observations
1, Think Aloud Method
Q: Briefly describe the "think aloud" technique.
A:
person is asked to speak out their thoughts while doing a task, e.g.:
– what they are trying to do, why they took an action
– how they interpret what the system did

Q: Name an advantage and a disadvantage.
A: 
advantages:
gives insight into what the person is thinking.
 
disvantages:
– may alter how people perform tasks
– unnatural (awkward & uncomfortable)
– hard to talk while concentrating

2, Constructive Interaction
• observe two people working together
– monitor their normal conversations
– removes awkwardness of think-aloud

• different version: co-discovery learning
– use semi-knowledgeable ‘coach’ and ‘novice’
– only novice uses the interface
	• novice to ask questions
	• coach responds
	
##### Interviews and Questionnaires
plan a set of central questions
– a few good questions to get things started
– avoid leading/suggestive questions (bias)
– focus on the interview
– could be based on results of user observations

semi-structured interview
– let user responses lead to follow-up questions
– follow interesting discussions

##### Continuous Evaluation
• monitor systems in actual use
– usually later stage of development
– fix problems in next release

• user feedback
– provide means of reporting feedback: help desks, bulletin boards, e-mail, etc.
– combine with trouble-shooting facilities

• case/field studies
– careful study of “system usage” on-site
– seeing system in “real-life” use
– monitor through external observers and site visits

### Qualitative Evaluation Techniques
qualitative techniques to evaluate non-numeric aspects of interfaces
a number of different techniques for evaluation
often combinations of techniques employed:
– e.g., questionnaire with open-ended interviewing
– e.g., single-person or team direct observation and think-aloud with co-discovery learning

results often not backed with statistics and may be biased (reduce as much as possible), but yield important insights into what people think
more general issues discovered